{"object":"list","data":[{"id":"deepseek-v3.1-4bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/DeepSeek-V3.1-4bit","name":"DeepSeek V3.1 (4-bit)","description":"DeepSeek V3.1 is a large language model trained on the DeepSeek V3.1 dataset.","context_length":0,"tags":[],"storage_size_megabytes":387072,"supports_tensor":true},{"id":"deepseek-v3.1-8bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/DeepSeek-V3.1-8bit","name":"DeepSeek V3.1 (8-bit)","description":"DeepSeek V3.1 is a large language model trained on the DeepSeek V3.1 dataset.","context_length":0,"tags":[],"storage_size_megabytes":730112,"supports_tensor":true},{"id":"kimi-k2-instruct-4bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Kimi-K2-Instruct-4bit","name":"Kimi K2 Instruct (4-bit)","description":"Kimi K2 is a large language model trained on the Kimi K2 dataset.","context_length":0,"tags":[],"storage_size_megabytes":591872,"supports_tensor":true},{"id":"kimi-k2-thinking","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Kimi-K2-Thinking","name":"Kimi K2 Thinking (4-bit)","description":"Kimi K2 Thinking is the latest, most capable version of open-source thinking model.","context_length":0,"tags":[],"storage_size_megabytes":673792,"supports_tensor":true},{"id":"llama-3.1-8b","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Meta-Llama-3.1-8B-Instruct-4bit","name":"Llama 3.1 8B (4-bit)","description":"Llama 3.1 is a large language model trained on the Llama 3.1 dataset.","context_length":0,"tags":[],"storage_size_megabytes":4423,"supports_tensor":true},{"id":"llama-3.1-8b-8bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Meta-Llama-3.1-8B-Instruct-8bit","name":"Llama 3.1 8B (8-bit)","description":"Llama 3.1 is a large language model trained on the Llama 3.1 dataset.","context_length":0,"tags":[],"storage_size_megabytes":8540,"supports_tensor":true},{"id":"llama-3.1-8b-bf16","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Meta-Llama-3.1-8B-Instruct-bf16","name":"Llama 3.1 8B (BF16)","description":"Llama 3.1 is a large language model trained on the Llama 3.1 dataset.","context_length":0,"tags":[],"storage_size_megabytes":16100,"supports_tensor":true},{"id":"llama-3.1-70b","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Meta-Llama-3.1-70B-Instruct-4bit","name":"Llama 3.1 70B (4-bit)","description":"Llama 3.1 is a large language model trained on the Llama 3.1 dataset.","context_length":0,"tags":[],"storage_size_megabytes":38769,"supports_tensor":true},{"id":"llama-3.2-1b","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Llama-3.2-1B-Instruct-4bit","name":"Llama 3.2 1B (4-bit)","description":"Llama 3.2 is a large language model trained on the Llama 3.2 dataset.","context_length":0,"tags":[],"storage_size_megabytes":696,"supports_tensor":true},{"id":"llama-3.2-3b","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Llama-3.2-3B-Instruct-4bit","name":"Llama 3.2 3B (4-bit)","description":"Llama 3.2 is a large language model trained on the Llama 3.2 dataset.","context_length":0,"tags":[],"storage_size_megabytes":1777,"supports_tensor":true},{"id":"llama-3.2-3b-8bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Llama-3.2-3B-Instruct-8bit","name":"Llama 3.2 3B (8-bit)","description":"Llama 3.2 is a large language model trained on the Llama 3.2 dataset.","context_length":0,"tags":[],"storage_size_megabytes":3339,"supports_tensor":true},{"id":"llama-3.3-70b","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Llama-3.3-70B-Instruct-4bit","name":"Llama 3.3 70B (4-bit)","description":"The Meta Llama 3.3 multilingual large language model (LLM) is an instruction tuned generative model in 70B (text in/text out)","context_length":0,"tags":[],"storage_size_megabytes":38769,"supports_tensor":true},{"id":"llama-3.3-70b-8bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Llama-3.3-70B-Instruct-8bit","name":"Llama 3.3 70B (8-bit)","description":"The Meta Llama 3.3 multilingual large language model (LLM) is an instruction tuned generative model in 70B (text in/text out)","context_length":0,"tags":[],"storage_size_megabytes":73242,"supports_tensor":true},{"id":"llama-3.3-70b-fp16","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/llama-3.3-70b-instruct-fp16","name":"Llama 3.3 70B (FP16)","description":"The Meta Llama 3.3 multilingual large language model (LLM) is an instruction tuned generative model in 70B (text in/text out)","context_length":0,"tags":[],"storage_size_megabytes":137695,"supports_tensor":true},{"id":"qwen3-0.6b","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Qwen3-0.6B-4bit","name":"Qwen3 0.6B (4-bit)","description":"Qwen3 0.6B is a large language model trained on the Qwen3 0.6B dataset.","context_length":0,"tags":[],"storage_size_megabytes":327,"supports_tensor":false},{"id":"qwen3-0.6b-8bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Qwen3-0.6B-8bit","name":"Qwen3 0.6B (8-bit)","description":"Qwen3 0.6B is a large language model trained on the Qwen3 0.6B dataset.","context_length":0,"tags":[],"storage_size_megabytes":666,"supports_tensor":false},{"id":"qwen3-30b","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Qwen3-30B-A3B-4bit","name":"Qwen3 30B A3B (4-bit)","description":"Qwen3 30B is a large language model trained on the Qwen3 30B dataset.","context_length":0,"tags":[],"storage_size_megabytes":16797,"supports_tensor":true},{"id":"qwen3-30b-8bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Qwen3-30B-A3B-8bit","name":"Qwen3 30B A3B (8-bit)","description":"Qwen3 30B is a large language model trained on the Qwen3 30B dataset.","context_length":0,"tags":[],"storage_size_megabytes":31738,"supports_tensor":true},{"id":"qwen3-80b-a3B-4bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Qwen3-Next-80B-A3B-Instruct-4bit","name":"Qwen3 80B A3B (4-bit)","description":"Qwen3 80B","context_length":0,"tags":[],"storage_size_megabytes":44800,"supports_tensor":true},{"id":"qwen3-80b-a3B-8bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Qwen3-Next-80B-A3B-Instruct-8bit","name":"Qwen3 80B A3B (8-bit)","description":"Qwen3 80B","context_length":0,"tags":[],"storage_size_megabytes":84700,"supports_tensor":true},{"id":"qwen3-80b-a3B-thinking-4bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Qwen3-Next-80B-A3B-Thinking-4bit","name":"Qwen3 80B A3B Thinking (4-bit)","description":"Qwen3 80B Reasoning model","context_length":0,"tags":[],"storage_size_megabytes":84700,"supports_tensor":true},{"id":"qwen3-80b-a3B-thinking-8bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Qwen3-Next-80B-A3B-Thinking-8bit","name":"Qwen3 80B A3B Thinking (8-bit)","description":"Qwen3 80B Reasoning model","context_length":0,"tags":[],"storage_size_megabytes":84700,"supports_tensor":true},{"id":"qwen3-235b-a22b-4bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Qwen3-235B-A22B-Instruct-2507-4bit","name":"Qwen3 235B A22B (4-bit)","description":"Qwen3 235B (Active 22B) is a large language model trained on the Qwen3 235B dataset.","context_length":0,"tags":[],"storage_size_megabytes":135168,"supports_tensor":true},{"id":"qwen3-235b-a22b-8bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Qwen3-235B-A22B-Instruct-2507-8bit","name":"Qwen3 235B A22B (8-bit)","description":"Qwen3 235B (Active 22B) is a large language model trained on the Qwen3 235B dataset.","context_length":0,"tags":[],"storage_size_megabytes":256000,"supports_tensor":true},{"id":"qwen3-coder-480b-a35b-4bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Qwen3-Coder-480B-A35B-Instruct-4bit","name":"Qwen3 Coder 480B A35B (4-bit)","description":"Qwen3 Coder 480B (Active 35B) is a large language model trained on the Qwen3 Coder 480B dataset.","context_length":0,"tags":[],"storage_size_megabytes":276480,"supports_tensor":true},{"id":"qwen3-coder-480b-a35b-8bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/Qwen3-Coder-480B-A35B-Instruct-8bit","name":"Qwen3 Coder 480B A35B (8-bit)","description":"Qwen3 Coder 480B (Active 35B) is a large language model trained on the Qwen3 Coder 480B dataset.","context_length":0,"tags":[],"storage_size_megabytes":552960,"supports_tensor":true},{"id":"gpt-oss-120b-MXFP4-Q8","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/gpt-oss-120b-MXFP4-Q8","name":"GPT-OSS 120B (MXFP4-Q8, MLX)","description":"OpenAI's GPT-OSS 120B is a 117B-parameter Mixture-of-Experts model designed for high-reasoning and general-purpose use; this variant is a 4-bit MLX conversion for Apple Silicon.","context_length":0,"tags":[],"storage_size_megabytes":67379,"supports_tensor":true},{"id":"gpt-oss-20b-4bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/gpt-oss-20b-MXFP4-Q4","name":"GPT-OSS 20B (MXFP4-Q4, MLX)","description":"OpenAI's GPT-OSS 20B is a medium-sized MoE model for lower-latency and local or specialized use cases; this MLX variant uses MXFP4 4-bit quantization.","context_length":0,"tags":[],"storage_size_megabytes":11468,"supports_tensor":true},{"id":"glm-4.5-air-8bit","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/GLM-4.5-Air-8bit","name":"GLM 4.5 Air 8bit","description":"GLM 4.5 Air 8bit","context_length":0,"tags":[],"storage_size_megabytes":116736,"supports_tensor":false},{"id":"glm-4.5-air-bf16","object":"model","created":1768745798,"owned_by":"exo","hugging_face_id":"mlx-community/GLM-4.5-Air-bf16","name":"GLM 4.5 Air bf16","description":"GLM 4.5 Air bf16","context_length":0,"tags":[],"storage_size_megabytes":219136,"supports_tensor":true}]}
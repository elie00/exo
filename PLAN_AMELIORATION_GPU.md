# Plan d'amÃ©lioration EXO : Support GPU NVIDIA (Linux)

## ðŸ“Š Ã‰tat actuel

### macOS (fonctionnel)
- âœ… **DÃ©tection GPU** : `macmon` collecte mÃ©triques GPU (usage, temp, power)
- âœ… **Backend MLX Metal** : `mlx>=0.30.1` utilise GPU Apple Silicon automatiquement
- âœ… **Device selection** : `mx.set_default_device(mx.gpu)` + `mx.metal.is_available()`
- âœ… **TÃ©lÃ©mÃ©trie** : `NodePerformanceProfile.system.gpu_usage` remontÃ© dans `/state`

### Linux (âœ… IMPLÃ‰MENTÃ‰)
- âœ… **DÃ©tection GPU** : `nvidia_monitor.py` via pynvml dÃ©tecte les GPU NVIDIA RTX
- âœ… **MLX CUDA** : Support via `mlx[cuda]>=0.30.1` avec `--extra cuda`
- âœ… **GGUF/llama.cpp CUDA** : `n_gpu_layers` calculÃ© automatiquement selon VRAM
- âœ… **Placement GPU-aware** : VRAM utilisÃ©e pour placement si `prefer_gpu=True`
- âœ… **TÃ©lÃ©mÃ©trie GPU** : VRAM, utilisation, tempÃ©rature exposÃ©s via `/gpu/info`
- âœ… **API endpoint** : `/gpu/info` retourne l'Ã©tat GPU de tous les nÅ“uds


---

## ðŸŽ¯ Objectifs

1. **DÃ©tecter les GPU NVIDIA** sur Linux (RTX 3050, etc.)
2. **Utiliser MLX avec CUDA** ou un backend alternatif (PyTorch CUDA)
3. **Exposer VRAM dans la topologie** pour le placement de modÃ¨les
4. **Collecter mÃ©triques GPU** (usage, temp, VRAM) comme sur macOS
5. **Permettre placement GPU-aware** (modÃ¨les sur GPU vs CPU selon disponibilitÃ©)

---

## ðŸ“‹ Plan d'implÃ©mentation (par prioritÃ©)

### Phase 1 : DÃ©tection GPU NVIDIA (Fondation)

#### 1.1 CrÃ©er module `exo/worker/utils/nvidia.py`
**Fichier** : `src/exo/worker/utils/nvidia.py`

```python
"""DÃ©tection et mÃ©triques GPU NVIDIA via NVML/pynvml."""
import platform
from typing import Optional

try:
    import pynvml
    NVML_AVAILABLE = True
except ImportError:
    NVML_AVAILABLE = False

class NvidiaGPUInfo:
    """Informations sur un GPU NVIDIA."""
    device_id: int
    name: str
    total_vram_bytes: int
    free_vram_bytes: int
    used_vram_bytes: int
    temperature: float
    power_usage_watts: float
    utilization_gpu_percent: float
    utilization_memory_percent: float

class NvidiaMonitor:
    """Monitor GPU NVIDIA (Ã©quivalent macmon pour macOS)."""
    
    @classmethod
    def is_available(cls) -> bool:
        """VÃ©rifie si NVML est disponible et fonctionnel."""
        if not NVML_AVAILABLE:
            return False
        if platform.system().lower() != "linux":
            return False
        try:
            pynvml.nvmlInit()
            pynvml.nvmlShutdown()
            return True
        except:
            return False
    
    @classmethod
    def get_gpu_count(cls) -> int:
        """Retourne le nombre de GPU NVIDIA dÃ©tectÃ©s."""
        if not cls.is_available():
            return 0
        pynvml.nvmlInit()
        try:
            return pynvml.nvmlDeviceGetCount()
        finally:
            pynvml.nvmlShutdown()
    
    @classmethod
    def get_gpu_info(cls, device_id: int = 0) -> Optional[NvidiaGPUInfo]:
        """RÃ©cupÃ¨re les infos d'un GPU spÃ©cifique."""
        # ImplÃ©mentation complÃ¨te avec pynvml
        pass
    
    @classmethod
    async def get_metrics_async(cls) -> Optional[dict]:
        """Retourne mÃ©triques GPU au format similaire Ã  macmon."""
        # Format compatible avec Metrics de macmon.py
        pass
```

**DÃ©pendances Ã  ajouter** :
- `pynvml` (wrapper Python pour NVML)
- Optionnel : `nvidia-ml-py` (alternative)

**Actions** :
- [ ] CrÃ©er `src/exo/worker/utils/nvidia.py`
- [ ] Ajouter `pynvml>=11.5.0` dans `pyproject.toml` (dÃ©pendance Linux-only)
- [ ] Tests unitaires pour dÃ©tection GPU

---

#### 1.2 IntÃ©grer dÃ©tection GPU dans `profile.py`
**Fichier** : `src/exo/worker/utils/profile.py`

**Modifications** :
```python
# Ligne 30-35 : Ajouter fallback NVIDIA
async def get_metrics_async() -> Metrics | None:
    """Return detailed Metrics on macOS or NVIDIA GPU on Linux."""
    if platform.system().lower() == "darwin":
        return await macmon_get_metrics_async()
    elif platform.system().lower() == "linux":
        # Nouveau : dÃ©tection NVIDIA
        from .nvidia import NvidiaMonitor
        if NvidiaMonitor.is_available():
            return await NvidiaMonitor.get_metrics_async()
    return None
```

**Actions** :
- [ ] Modifier `get_metrics_async()` pour appeler `NvidiaMonitor`
- [ ] Adapter `start_polling_node_metrics()` pour utiliser mÃ©triques NVIDIA
- [ ] Mapper `NvidiaGPUInfo` â†’ `SystemPerformanceProfile` (gpu_usage, temp, etc.)

---

#### 1.3 Exposer VRAM dans `NodePerformanceProfile`
**Fichier** : `src/exo/shared/types/profiling.py`

**Modifications** :
```python
class MemoryPerformanceProfile(CamelCaseModel):
    ram_total: Memory
    ram_available: Memory
    swap_total: Memory
    swap_available: Memory
    # NOUVEAU : VRAM GPU
    gpu_vram_total: Memory | None = None
    gpu_vram_available: Memory | None = None
    gpu_vram_used: Memory | None = None

class SystemPerformanceProfile(CamelCaseModel):
    gpu_usage: float = 0.0
    temp: float = 0.0
    sys_power: float = 0.0
    pcpu_usage: float = 0.0
    ecpu_usage: float = 0.0
    ane_power: float = 0.0
    # NOUVEAU : Infos GPU dÃ©taillÃ©es
    gpu_count: int = 0
    gpu_names: list[str] = []
    gpu_power_watts: float = 0.0
```

**Actions** :
- [ ] Ajouter champs VRAM dans `MemoryPerformanceProfile`
- [ ] Ajouter `gpu_count`, `gpu_names` dans `SystemPerformanceProfile`
- [ ] Mettre Ã  jour `apply.py` pour initialiser ces champs
- [ ] Mettre Ã  jour dashboard pour afficher VRAM

---

### Phase 2 : Backend MLX CUDA (Utilisation GPU)

#### 2.1 Activer MLX CUDA dans `pyproject.toml`
**Fichier** : `pyproject.toml`

**Modifications** :
```toml
# Ligne 33 : Conditionner selon disponibilitÃ© CUDA
"mlx[cpu]>=0.30.1; sys_platform == 'linux' and not cuda_available()",
"mlx[cuda]>=0.30.1; sys_platform == 'linux' and cuda_available()",

# Ligne 56-59 : DÃ©commenter et amÃ©liorer
[project.optional-dependencies]
cuda = [
    "mlx[cuda]>=0.30.1",
    "pynvml>=11.5.0",
]

# Ajouter fonction helper pour dÃ©tecter CUDA
# (peut nÃ©cessiter setup.py ou pyproject.toml dynamique)
```

**ProblÃ¨me** : `pyproject.toml` ne supporte pas de logique Python dynamique.

**Solution alternative** :
- CrÃ©er `setup_cuda.py` qui dÃ©tecte CUDA et installe `mlx[cuda]` si disponible
- Ou utiliser variable d'environnement `EXO_USE_CUDA=1` pour forcer CUDA

**Actions** :
- [ ] CrÃ©er script `scripts/detect_cuda.py` pour vÃ©rifier CUDA
- [ ] Modifier installation pour proposer `uv sync --extra cuda` si CUDA dÃ©tectÃ©
- [ ] Documenter dans README comment activer CUDA

---

#### 2.2 DÃ©tection automatique device MLX (GPU vs CPU)
**Fichier** : `src/exo/worker/engines/mlx/utils_mlx.py`

**Modifications** :
```python
# Ligne 164-174 : initialize_mlx()
def initialize_mlx(bound_instance: BoundInstance) -> Group:
    mx.random.seed(42)
    
    # NOUVEAU : DÃ©tecter device disponible
    device_type = _detect_mlx_device()
    if device_type == "gpu":
        mx.set_default_device(mx.gpu)
        logger.info("Using MLX GPU backend")
    elif device_type == "cuda":
        # MLX CUDA si disponible
        mx.set_default_device(mx.cuda)  # ou Ã©quivalent
        logger.info("Using MLX CUDA backend")
    else:
        mx.set_default_device(mx.cpu)
        logger.info("Using MLX CPU backend (fallback)")
    
    # ... reste du code

def _detect_mlx_device() -> str:
    """DÃ©tecte le meilleur device MLX disponible."""
    if mx.metal.is_available():
        return "gpu"
    # TODO: VÃ©rifier mlx.cuda.is_available() si MLX CUDA existe
    # if hasattr(mx, 'cuda') and mx.cuda.is_available():
    #     return "cuda"
    return "cpu"
```

**Actions** :
- [ ] Ajouter `_detect_mlx_device()` dans `utils_mlx.py`
- [ ] Modifier `initialize_mlx()` pour sÃ©lectionner device automatiquement
- [ ] Tester avec MLX CUDA si disponible

---

#### 2.3 Alternative : Backend PyTorch CUDA (si MLX CUDA indisponible)
**Fichier** : `src/exo/worker/engines/pytorch/` (nouveau)

**Si MLX CUDA n'est pas mature**, crÃ©er un backend PyTorch alternatif :

```python
# src/exo/worker/engines/pytorch/utils_pytorch.py
import torch

def initialize_pytorch_cuda() -> bool:
    """Initialise PyTorch avec CUDA si disponible."""
    if torch.cuda.is_available():
        torch.cuda.set_device(0)
        return True
    return False

def load_model_pytorch(model_path: str):
    """Charge modÃ¨le avec PyTorch CUDA."""
    # ImplÃ©mentation similaire Ã  load_mlx_items()
    pass
```

**Actions** :
- [ ] Ã‰valuer si MLX CUDA est stable (vÃ©rifier docs MLX)
- [ ] Si non, crÃ©er backend PyTorch optionnel
- [ ] Ajouter `torch>=2.0.0` dans optional-dependencies

---

### Phase 3 : Placement GPU-aware

#### 3.1 Modifier placement pour considÃ©rer VRAM
**Fichier** : `src/exo/master/placement_utils.py`

**Modifications** :
```python
def filter_cycles_by_memory(
    cycles: list[list[NodeInfo]],
    required_memory: Memory,
    prefer_gpu: bool = True
) -> list[list[NodeInfo]]:
    """Filtre cycles selon mÃ©moire disponible (RAM ou VRAM si GPU)."""
    valid_cycles = []
    for cycle in cycles:
        total_available = Memory()
        gpu_available = Memory()
        
        for node in cycle:
            if node.node_profile:
                # RAM systÃ¨me
                total_available += node.node_profile.memory.ram_available
                # VRAM GPU (si disponible)
                if node.node_profile.memory.gpu_vram_available:
                    gpu_available += node.node_profile.memory.gpu_vram_available
        
        # PrÃ©fÃ©rer VRAM si disponible et si prefer_gpu=True
        effective_memory = gpu_available if (prefer_gpu and gpu_available.in_bytes > 0) else total_available
        
        if effective_memory >= required_memory:
            valid_cycles.append(cycle)
    
    return valid_cycles
```

**Actions** :
- [ ] Modifier `filter_cycles_by_memory()` pour utiliser VRAM
- [ ] Ajouter paramÃ¨tre `prefer_gpu` dans `PlaceInstance` command
- [ ] Mettre Ã  jour `place_instance()` pour passer `prefer_gpu=True` si GPU dÃ©tectÃ©

---

#### 3.2 Exposer prÃ©fÃ©rence GPU dans API
**Fichier** : `src/exo/master/api.py`

**Modifications** :
```python
# Ligne 178-191 : place_instance()
async def place_instance(self, payload: PlaceInstanceParams):
    command = PlaceInstance(
        model_meta=await resolve_model_meta(payload.model_id),
        sharding=payload.sharding,
        instance_meta=payload.instance_meta,
        min_nodes=payload.min_nodes,
        prefer_gpu=payload.prefer_gpu,  # NOUVEAU
    )
    # ...
```

**Actions** :
- [ ] Ajouter `prefer_gpu: bool = True` dans `PlaceInstanceParams`
- [ ] Exposer dans `/instance/previews` les placements GPU vs CPU
- [ ] Dashboard : afficher indicateur "GPU" vs "CPU" pour chaque preview

---

### Phase 4 : Dashboard & ObservabilitÃ©

#### 4.1 Afficher VRAM dans dashboard
**Fichier** : `dashboard/src/lib/components/` (TopologyGraph ou NodeCard)

**Modifications** :
- Afficher barre VRAM sÃ©parÃ©e de RAM si `gpu_vram_total` existe
- Afficher nom GPU (`gpu_names[0]`) dans tooltip node
- Indicateur visuel "GPU" vs "CPU" sur chaque node

**Actions** :
- [ ] Modifier composants dashboard pour lire `gpu_vram_*`
- [ ] Ajouter lÃ©gende "VRAM" dans graphique mÃ©moire
- [ ] Afficher tempÃ©rature GPU si disponible

---

#### 4.2 Logs & mÃ©triques GPU
**Fichier** : `src/exo/worker/main.py`

**Modifications** :
- Logger au dÃ©marrage : "GPU detected: NVIDIA RTX 3050 (8GB VRAM)"
- Logger si fallback CPU : "Warning: GPU detected but MLX CUDA not available, using CPU"

**Actions** :
- [ ] Ajouter logs informatifs sur dÃ©tection GPU
- [ ] Exposer mÃ©triques GPU dans `/state` (dÃ©jÃ  fait via `NodePerformanceProfile`)

---

## ðŸ”§ DÃ©pendances Ã  ajouter

### Obligatoires (Linux avec GPU)
```toml
# pyproject.toml
[project.optional-dependencies]
cuda = [
    "mlx[cuda]>=0.30.1",  # Si MLX CUDA stable
    "pynvml>=11.5.0",     # DÃ©tection GPU NVIDIA
]
# OU alternative PyTorch
pytorch-cuda = [
    "torch>=2.0.0",
    "pynvml>=11.5.0",
]
```

### Installation
```bash
# DÃ©tecter CUDA automatiquement
uv sync --extra cuda

# Ou manuellement
export EXO_USE_CUDA=1
uv sync --extra cuda
```

---

## ðŸ“Š MÃ©triques de succÃ¨s

1. âœ… **DÃ©tection** : `curl http://localhost:52415/state | jq '.topology.nodes[].node_profile.system.gpu_count'` â†’ `1` (au lieu de `0`)
2. âœ… **VRAM exposÃ©e** : `jq '.topology.nodes[].node_profile.memory.gpu_vram_total'` â†’ `8589934592` (8GB)
3. âœ… **Utilisation GPU** : Logs montrent "Using MLX CUDA backend" au dÃ©marrage
4. âœ… **Performance** : InfÃ©rence 5-10x plus rapide sur GPU vs CPU (mesurer tokens/sec)

---

## ðŸš¨ Risques & Limitations

1. **MLX CUDA peut Ãªtre instable** : VÃ©rifier version MLX supporte CUDA avant dÃ©ploiement
2. **CompatibilitÃ© drivers** : NÃ©cessite NVIDIA drivers >= 525.x + CUDA >= 12.0
3. **Fallback CPU** : Si CUDA indisponible, exo doit continuer sur CPU sans crash
4. **Multi-GPU** : Plan futur pour utiliser plusieurs GPU sur un mÃªme node

---

## ðŸ“… Estimation

- **Phase 1** (DÃ©tection) : 2-3 jours
- **Phase 2** (Backend CUDA) : 3-5 jours (selon stabilitÃ© MLX CUDA)
- **Phase 3** (Placement) : 1-2 jours
- **Phase 4** (Dashboard) : 1-2 jours

**Total** : ~1-2 semaines de dev + tests

---

## ðŸ”— RÃ©fÃ©rences

- [MLX CUDA Support](https://github.com/ml-explore/mlx) (vÃ©rifier si disponible)
- [pynvml Documentation](https://pypi.org/project/nvidia-ml-py/)
- [NVIDIA Management Library (NVML)](https://developer.nvidia.com/nvidia-management-library-nvml)
